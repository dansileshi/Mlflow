{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "716142fc",
   "metadata": {},
   "source": [
    "# Machine Learning Experimentation with MLflow, TensorFlow, and CatBoost\n",
    "\n",
    "In this tutorial, we demonstrate a comprehensive machine learning workflow using MLflow for experiment tracking, TensorFlow for building neural network models, and CatBoost for gradient boosting models. Our objective is to predict the median income of households in California districts, based on several features such as median income, housing average age, and geographical location.\n",
    "\n",
    "## Experiment Setup with MLflow\n",
    "\n",
    "MLflow is an open-source platform for managing the end-to-end machine learning lifecycle. It includes features for experiment tracking, model versioning, and deployment. MLflow helps in comparing different models and tracking experiments to ensure reproducibility.\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"income\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792319bb",
   "metadata": {},
   "source": [
    "# MLflow UI Overview\n",
    "\n",
    "MLflow UI is an integral part of the MLflow platform, designed to simplify the management and analysis of machine learning experiments. It offers a comprehensive interface for tracking experiments, comparing model performances, and versioning models. Here's a closer look at the functionalities provided by the MLflow UI:\n",
    "\n",
    "## Experiment Tracking\n",
    "\n",
    "- **Log Parameters and Metrics**: Users can log various parameters (e.g., hyperparameters, feature sets) and metrics (e.g., accuracy, RMSE) for each run, facilitating detailed performance analysis.\n",
    "\n",
    "- **Visual Comparisons**: The UI allows for side-by-side comparisons of different runs, making it easy to identify the best-performing models based on their metrics.\n",
    "\n",
    "- **Artifact Storage**: Artifacts such as model binaries, plots, and additional files generated during the runs can be stored and accessed through the UI. This feature supports in-depth analysis and review of model outputs and diagnostics.\n",
    "\n",
    "## Model Management\n",
    "\n",
    "- **Model Versioning**: MLflow UI aids in managing different versions of models, tracking their performance over time, and selecting the best version for deployment.\n",
    "\n",
    "- **Run History**: It provides a detailed history of runs, including start and end times, parameters, metrics, and tags. This historical view helps in understanding model improvements and iterations over time.\n",
    "\n",
    "## Visualization and Analysis\n",
    "\n",
    "- **Metric Plots**: The UI offers plotting capabilities for metrics over time, allowing users to visually assess model training dynamics, overfitting, or convergence.\n",
    "\n",
    "- **Custom Queries**: Users can query and filter runs based on specific metrics, parameters, or tags, enabling targeted analysis of experiments.\n",
    "\n",
    "## Collaboration and Sharing\n",
    "\n",
    "- **Experiment Sharing**: The platform supports sharing experiments and results with team members, facilitating collaboration on machine learning projects.\n",
    "\n",
    "- **Annotation and Tagging**: Runs can be annotated with tags or comments, providing additional context or insights for future reference.\n",
    "\n",
    "The MLflow UI is accessible via a web browser, making it a user-friendly tool for data scientists and engineers to monitor and analyze their machine learning experiments effectively. Its integration with the broader MLflow platform ensures a seamless workflow for experiment tracking, model tuning, and deployment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0cbf30",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "At the end of the experiment, you will encounter an interface in the MLflow UI similar to the one depicted below. This interface provides a comprehensive overview of your experiment's results, including metrics, parameters, and artifacts, enabling you to analyze the performance of various models at a glance.\n",
    "\n",
    "![MLflow UI Experiment Overview](./images/Screenshot.png)\n",
    "\n",
    "This visual representation in the MLflow UI simplifies the comparison between different runs, helping you to identify the most effective model configurations and make informed decisions about which models to further develop or deploy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tabtransformertf.models.fttransformer import FTTransformerEncoder, FTTransformer\n",
    "from tabtransformertf.utils.preprocessing import df_to_dataset\n",
    "\n",
    "import catboost as cb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12e4647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.rcParams.update({'font.size': 15})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fe71b4",
   "metadata": {},
   "source": [
    "The command `mlflow ui --backend-store-uri sqlite://mlflow.db` is used to launch the MLflow user interface (UI) locally. MLflow is an open-source platform for managing the end-to-end machine learning lifecycle. \n",
    "\n",
    "Here's what each part of the command does:\n",
    "\n",
    "- `mlflow ui`: This part of the command launches the MLflow UI, which provides a graphical interface for users to interact with MLflow components such as experiments, runs, parameters, metrics, and artifacts.\n",
    "\n",
    "- `--backend-store-uri sqlite://mlflow.db`: This part specifies the backend store URI for MLflow. In this case, it's using SQLite as the backend store, and `mlflow.db` is the SQLite database file where MLflow will store metadata such as experiment and run information.\n",
    "\n",
    "So, when you run this command, MLflow will start a local server hosting its UI, and it will use SQLite as the backend store to persist metadata related to experiments and runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b46af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow ui --backend-store-uri sqlite://mlflow.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fd78161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///d:/Mlflow/tutorials-main/mlflow/tutorials/mlflow/mlruns/1', creation_time=1707252810494, experiment_id='1', last_update_time=1707252810494, lifecycle_stage='active', name='income', tags={}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70578a3e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e16a2775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = fetch_california_housing()\n",
    "data = dset['data']\n",
    "y = dset['target']\n",
    "LABEL = dset['target_names'][0]\n",
    "\n",
    "NUMERIC_FEATURES = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Longitude', 'Latitude']\n",
    "FEATURES = NUMERIC_FEATURES\n",
    "\n",
    "data = pd.DataFrame(data, columns=dset['feature_names'])\n",
    "data[LABEL] = y\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a43a381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (16512, 9)\n",
      "Test dataset shape: (4128, 9)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "print(f\"Train dataset shape: {train_data.shape}\")\n",
    "print(f\"Test dataset shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768867d8",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "## Feature Scaling\n",
    "\n",
    "Before training our models, it's crucial to apply feature scaling to ensure all numeric features contribute equally to the model's performance. This is especially important for models that are sensitive to the scale of the input features, such as neural networks and models that use distance measures.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d3107e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6732f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train.loc[:, NUMERIC_FEATURES] = sc.fit_transform(X_train[NUMERIC_FEATURES])\n",
    "X_val.loc[:, NUMERIC_FEATURES] = sc.transform(X_val[NUMERIC_FEATURES])\n",
    "test_data.loc[:, NUMERIC_FEATURES] = sc.transform(test_data[NUMERIC_FEATURES])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb799fb",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "### Model with RandomForestRegressor\n",
    "The RandomForestRegressor serves as our baseline model. It's an ensemble method that builds multiple decision trees and merges them for a more accurate and robust prediction. This model is known for its ability to handle complex datasets with a mix of numerical and categorical features effectively.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7a73f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\mlflow_env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlflow.sklearn.autolog(disable=True)\n",
    "\n",
    "with mlflow.start_run(run_name='rf_baseline'):\n",
    "    params = {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 20\n",
    "    }\n",
    "\n",
    "    mlflow.set_tag(\"model_name\", \"RF\")\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=20)\n",
    "    rf.fit(X_train[FEATURES], X_train[LABEL])\n",
    "\n",
    "    rf_preds = rf.predict(test_data[FEATURES])\n",
    "    rf_rms = mean_squared_error(test_data[LABEL], rf_preds, squared=False)\n",
    "\n",
    "    mlflow.log_metric(\"test_rmse\", rf_rms)\n",
    "    mlflow.sklearn.log_model(rf, \"sk_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bb7201",
   "metadata": {},
   "source": [
    "### CatBoost Model\n",
    "Next, we use CatBoost, a gradient boosting library that excels in dealing with categorical features directly, without the need for extensive preprocessing. CatBoost is designed to provide state-of-the-art results with minimal tuning and is particularly user-friendly for both regression and classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "056dbf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "catb_train_dataset = cb.Pool(X_train[FEATURES], X_train[LABEL]) \n",
    "catb_val_dataset = cb.Pool(X_val[FEATURES], X_val[LABEL]) \n",
    "catb_test_dataset = cb.Pool(test_data[FEATURES], test_data[LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0355894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"catboost\"):\n",
    "    mlflow.set_tag(\"model_name\", \"CatBoost\")\n",
    "    catb = cb.CatBoostRegressor()\n",
    "    catb.fit(catb_train_dataset, eval_set=catb_val_dataset, early_stopping_rounds=50)\n",
    "    catb_preds = catb.predict(catb_test_dataset)\n",
    "    catb_rms = mean_squared_error(test_data[LABEL], catb_preds, squared=False)\n",
    "\n",
    "    mlflow.log_metric(\"test_rmse\", catb_rms)\n",
    "    mlflow.catboost.log_model(catb, \"cb_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03687c96",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron (MLP) Model\n",
    "Finally, we explore a Multi-layer Perceptron (MLP), a type of neural network that consists of at least three layers of nodes: an input layer, hidden layers, and an output layer. MLPs can capture complex relationships in data by adjusting weights through backpropagation. In this context,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8cfc937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import mlflow\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def build_mlp(params):\n",
    "    \"\"\"\n",
    "    Builds a Multi-layer Perceptron model based on provided parameters.\n",
    "    \n",
    "    :param params: A dictionary containing model configuration like layer sizes and dropout rate.\n",
    "    :return: A compiled Keras Sequential model.\n",
    "    \"\"\"\n",
    "    # Define the MLP model architecture\n",
    "    mlp = Sequential([\n",
    "        Dense(params[\"layer1_size\"], activation=params['activation']),\n",
    "        Dropout(params['dropout_rate']),\n",
    "        Dense(params[\"layer2_size\"], activation=params['activation']),\n",
    "        Dropout(params['dropout_rate']),\n",
    "        Dense(1, activation='relu')  # Output layer for regression\n",
    "    ])\n",
    "    return mlp\n",
    "\n",
    "def train_mlp(mlp, train_params, train_dataset, val_dataset):\n",
    "    \"\"\"\n",
    "    Compiles and trains the MLP model using provided training parameters and datasets.\n",
    "    \n",
    "    :param mlp: The MLP model to be trained.\n",
    "    :param train_params: A dictionary with training configuration such as learning rate and weight decay.\n",
    "    :param train_dataset: The dataset for training the model.\n",
    "    :param val_dataset: The dataset for validating the model performance.\n",
    "    :return: The trained MLP model.\n",
    "    \"\"\"\n",
    "    # Configure the optimizer with weight decay\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=train_params[\"learning_rate\"],\n",
    "        weight_decay=train_params[\"weight_decay\"],\n",
    "    )\n",
    "\n",
    "    # Compile the model with loss and metrics\n",
    "    mlp.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=MeanSquaredError(name=\"mse\"),\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")]\n",
    "    )\n",
    "\n",
    "    # Early stopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_rmse\",\n",
    "        mode=\"min\",\n",
    "        patience=train_params[\"early_stop_patience\"],\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    mlp.fit(\n",
    "        train_dataset,\n",
    "        epochs=train_params[\"num_epochs\"],\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=[early_stopping],\n",
    "    )\n",
    "    return mlp\n",
    "\n",
    "def mlp_mlflow_run(name, mlp_params, train_params, train_dataset, val_dataset, test_dataset, y_test):\n",
    "    \"\"\"\n",
    "    Wrapper function to train the MLP model and log the experiment with MLflow.\n",
    "    \n",
    "    :param name: The name of the MLflow run.\n",
    "    :param mlp_params: Model parameters for building the MLP.\n",
    "    :param train_params: Training parameters.\n",
    "    :param train_dataset: Training dataset.\n",
    "    :param val_dataset: Validation dataset.\n",
    "    :param test_dataset: Test dataset for final evaluation.\n",
    "    :param y_test: True labels for the test dataset.\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        mlflow.log_params(mlp_params)\n",
    "        mlflow.log_params(train_params)\n",
    "        mlflow.set_tag(\"model_name\", \"MLP\")\n",
    "\n",
    "        # Build, train, and evaluate the model\n",
    "        mlp = build_mlp(mlp_params)\n",
    "        mlp = train_mlp(mlp, train_params, train_dataset, val_dataset)\n",
    "\n",
    "        test_preds = mlp.predict(test_dataset)\n",
    "        test_rms = mean_squared_error(y_test, test_preds.ravel(), squared=False)\n",
    "        \n",
    "\n",
    "        mlflow.log_metric(\"test_rmse\", test_rms)\n",
    "        mlflow.tensorflow.log_model(mlp, \"tf_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b89274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To TF Dataset\n",
    "mlp_train_ds = tf.data.Dataset.from_tensor_slices((X_train[FEATURES], X_train[LABEL])).batch(512).shuffle(512*4).prefetch(512)\n",
    "mlp_val_ds = tf.data.Dataset.from_tensor_slices((X_val[FEATURES], X_val[LABEL])).batch(512).shuffle(512*4).prefetch(512)\n",
    "mlp_test_ds = tf.data.Dataset.from_tensor_slices(test_data[FEATURES]).batch(512).prefetch(512)\n",
    "\n",
    "mlp_params = {\n",
    "    \"layer1_size\": 512,\n",
    "    \"layer2_size\": 128,\n",
    "    \"layer3_size\": 64,\n",
    "    \"dropout_rate\": 0.3,\n",
    "    \"activation\": 'relu'\n",
    "\n",
    "}\n",
    "train_params = dict(\n",
    "    learning_rate=0.008, weight_decay=0.00001, early_stop_patience=10, num_epochs=1000\n",
    ")\n",
    "\n",
    "mlp_mlflow_run(\n",
    "    \"mlp_base\",\n",
    "    mlp_params,\n",
    "    train_params,\n",
    "    mlp_train_ds,\n",
    "    mlp_val_ds,\n",
    "    mlp_test_ds,\n",
    "    test_data[LABEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1c2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlp_params = {\n",
    "    \"layer1_size\": 512,\n",
    "    \"layer2_size\": 264,\n",
    "    \"layer3_size\": 64,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"activation\": 'relu'\n",
    "\n",
    "}\n",
    "train_params = dict(\n",
    "    learning_rate=0.001, weight_decay=0.00001, early_stop_patience=30, num_epochs=1000\n",
    ")\n",
    "\n",
    "mlp_mlflow_run(\n",
    "    \"mlp_base_5\",\n",
    "    mlp_params,\n",
    "    train_params,\n",
    "    mlp_train_ds,\n",
    "    mlp_val_ds,\n",
    "    mlp_test_ds,\n",
    "    test_data[LABEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78bfdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mlflow_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c081d",
   "metadata": {},
   "source": [
    "## FT Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d91e1468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To TF Dataset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def df_to_dataset(dataframe, target=None, shuffle=True, batch_size=32):\n",
    "    df = dataframe.copy()\n",
    "    if target:\n",
    "        labels = df.pop(target).values\n",
    "        # Convert dataframe to a dictionary of series, then to a dictionary of numpy arrays\n",
    "        dataset = {key: value.values[:, np.newaxis] for key, value in df.items()}  # Adjusted line\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((dataset, labels))\n",
    "    else:\n",
    "        dataset = {key: value.values[:, np.newaxis] for key, value in df.items()}  # Adjusted line\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(dataframe))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = df_to_dataset(X_train[FEATURES + [LABEL]], LABEL, shuffle=True)\n",
    "val_dataset = df_to_dataset(X_val[FEATURES + [LABEL]], LABEL, shuffle=False)  # No shuffle\n",
    "test_dataset = df_to_dataset(test_data[FEATURES], shuffle=False) # No target, no shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c9766fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fttransformer(\n",
    "    params_to_log, params_to_skip, out_dim=1, out_activation=\"relu\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds an FTTransformer model with specified parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - params_to_log: Dictionary of parameters that will be logged and used in the FTTransformerEncoder.\n",
    "    - params_to_skip: Dictionary of parameters to skip during logging but used in the FTTransformerEncoder.\n",
    "    - out_dim: Output dimension of the final layer. Default is 1.\n",
    "    - out_activation: Activation function for the output layer. Default is \"relu\".\n",
    "\n",
    "    Returns:\n",
    "    - An FTTransformer model ready for training.\n",
    "    \"\"\"\n",
    "    # Define encoder\n",
    "    ft_encoder = FTTransformerEncoder(\n",
    "        **params_to_log,\n",
    "        **params_to_skip\n",
    "    )\n",
    "    # Add prediction head to the encoder\n",
    "    ft_transformer = FTTransformer(\n",
    "        encoder=ft_encoder,\n",
    "        out_dim=out_dim,\n",
    "        out_activation=out_activation,\n",
    "    )\n",
    "\n",
    "    return ft_transformer\n",
    "\n",
    "\n",
    "def train_model(model, train_params, train_dataset, val_dataset):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=train_params[\"learning_rate\"],\n",
    "        weight_decay=train_params[\"weight_decay\"],\n",
    "    )\n",
    "    \"\"\"\n",
    "    Compiles and trains the given model using specified parameters and datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model to train.\n",
    "    - train_params: Training parameters including learning rate and weight decay.\n",
    "    - train_dataset: The dataset for training the model.\n",
    "    - val_dataset: The dataset for validating the model performance.\n",
    "\n",
    "    Returns:\n",
    "    - The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss={\n",
    "            \"output\": tf.keras.losses.MeanSquaredError(name=\"mse\"),\n",
    "            \"importances\": None,\n",
    "        },\n",
    "        metrics={\n",
    "            \"output\": [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")],\n",
    "            \"importances\": None,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    early = EarlyStopping(\n",
    "        monitor=\"val_output_loss\",\n",
    "        mode=\"min\",\n",
    "        patience=train_params[\"early_stop_patience\"],\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "    callback_list = [early]\n",
    "\n",
    "    hist = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=train_params[\"num_epochs\"],\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=callback_list,\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7b38b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tensorflow.autolog(disable=True)\n",
    "\n",
    "\n",
    "import mlflow\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming build_fttransformer and train_model functions are defined as per previous refinements\n",
    "\n",
    "def fttransformer_mlflow_run(\n",
    "    name: str,\n",
    "    encoder_params: dict,\n",
    "    train_params: dict,\n",
    "    params_to_skip: dict,\n",
    "    train_dataset: tf.data.Dataset,\n",
    "    val_dataset: tf.data.Dataset,\n",
    "    test_dataset: tf.data.Dataset,\n",
    "    y_test: np.ndarray,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains an FTTransformer model and logs the experiment using MLflow.\n",
    "\n",
    "    Parameters:\n",
    "    - name: Name of the MLflow run.\n",
    "    - encoder_params: Parameters for the FTTransformer encoder.\n",
    "    - train_params: Training parameters.\n",
    "    - params_to_skip: Parameters to exclude from logging but include in model building.\n",
    "    - train_dataset: Dataset for training.\n",
    "    - val_dataset: Dataset for validation.\n",
    "    - test_dataset: Dataset for testing.\n",
    "    - y_test: Actual labels for the test dataset.\n",
    "\n",
    "    This function logs the encoder and training parameters, model architecture, and test performance metrics in MLflow.\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        mlflow.set_tag(\"model_name\", \"FTTransformer\")\n",
    "\n",
    "        # Log encoder and training parameters\n",
    "        mlflow.log_params(encoder_params)\n",
    "        mlflow.log_params(train_params)\n",
    "\n",
    "        # Disable automatic logging to customize what gets logged\n",
    "        mlflow.tensorflow.autolog(disable=True)\n",
    "\n",
    "        # Build and train the FTTransformer model\n",
    "        ft_transformer = build_fttransformer(\n",
    "            encoder_params,\n",
    "            params_to_skip,\n",
    "            out_dim=1,\n",
    "            out_activation=\"relu\",\n",
    "        )\n",
    "        ft_transformer = train_model(\n",
    "            ft_transformer, train_params, train_dataset, val_dataset\n",
    "        )\n",
    "\n",
    "        # Evaluate the model on the test dataset\n",
    "        test_preds = ft_transformer.predict(test_dataset)\n",
    "        test_rms = mean_squared_error(y_test, test_preds.ravel(), squared=False)\n",
    "\n",
    "        # Log the test RMSE\n",
    "        mlflow.log_metric(\"test_rmse\", test_rms)\n",
    "\n",
    "        # Log the FTTransformer model in MLflow\n",
    "        # Ensure to specify the TensorFlow model's save format as 'tf' for compatibility\n",
    "        mlflow.tensorflow.log_model(tf_model=ft_transformer, artifact_path=\"tf_models\", registered_model_name=\"FTTransformer\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5680ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = dict(\n",
    "    learning_rate=0.001, weight_decay=0.00001, early_stop_patience=10, num_epochs=1000\n",
    ")\n",
    "\n",
    "params_to_skip = dict(\n",
    "    numerical_data=X_train[NUMERIC_FEATURES].values,\n",
    "    categorical_data=None,\n",
    "    y=X_train[LABEL].values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e979ac",
   "metadata": {},
   "source": [
    "### Linear Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9247cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_embeddings_params = dict(\n",
    "    numerical_features=NUMERIC_FEATURES,\n",
    "    categorical_features=[],\n",
    "    numerical_embedding_type=\"linear\",\n",
    "    embedding_dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3,\n",
    "    explainable=True,\n",
    ")\n",
    "\n",
    "fttransformer_mlflow_run(\n",
    "    name='linear',\n",
    "    encoder_params=linear_embeddings_params,\n",
    "    train_params=train_params,\n",
    "    params_to_skip=params_to_skip,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    y_test=test_data[LABEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af43cb7a",
   "metadata": {},
   "source": [
    "### Periodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab954586",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_params_to_log = dict(\n",
    "    numerical_features=NUMERIC_FEATURES,\n",
    "    categorical_features=[],\n",
    "    numerical_embedding_type='periodic',\n",
    "    numerical_bins=128,\n",
    "    embedding_dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3,\n",
    "    explainable=True,\n",
    ")\n",
    "\n",
    "fttransformer_mlflow_run(\n",
    "    name='periodic',\n",
    "    encoder_params=periodic_params_to_log,\n",
    "    train_params=train_params,\n",
    "    params_to_skip=params_to_skip,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    y_test=test_data[LABEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804404f",
   "metadata": {},
   "source": [
    "### PLE - Quantile Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99796911",
   "metadata": {},
   "outputs": [],
   "source": [
    "pleq_params_to_log = dict(\n",
    "    numerical_features=NUMERIC_FEATURES,\n",
    "    categorical_features=[],\n",
    "    numerical_embedding_type='ple',\n",
    "    numerical_bins=128,\n",
    "    embedding_dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3,\n",
    "    explainable=True,\n",
    ")\n",
    "\n",
    "pleq_params_to_skip = params_to_skip.copy()\n",
    "pleq_params_to_skip['y'] = None\n",
    "\n",
    "fttransformer_mlflow_run(\n",
    "    name='ple_quantile',\n",
    "    encoder_params=pleq_params_to_log,\n",
    "    train_params=train_params,\n",
    "    params_to_skip=pleq_params_to_skip,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    y_test=test_data[LABEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9b6b4c",
   "metadata": {},
   "source": [
    "### PLE - Target Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6fd366",
   "metadata": {},
   "outputs": [],
   "source": [
    "plet_params_to_log = dict(\n",
    "    numerical_features=NUMERIC_FEATURES,\n",
    "    categorical_features=[],\n",
    "    numerical_embedding_type='ple',\n",
    "    numerical_bins=128,\n",
    "    embedding_dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3,\n",
    "    explainable=True,\n",
    "    task='regression',\n",
    "    ple_tree_params = {\n",
    "        \"min_samples_leaf\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "fttransformer_mlflow_run(\n",
    "    name='ple_target',\n",
    "    encoder_params=plet_params_to_log,\n",
    "    train_params=train_params,\n",
    "    params_to_skip=params_to_skip,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    y_test=test_data[LABEL],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c32fee20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\anaconda3\\envs\\mlflow_env\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [tensorflow] From c:\\Users\\User\\anaconda3\\envs\\mlflow_env\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_id = \"runs:/1dedda07d5b74951bee1226cdffdfdb0/tf_models\" # take it from mlflow\n",
    "loaded_ft = mlflow.tensorflow.load_model(model_id)\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cae1264",
   "metadata": {},
   "source": [
    "# Model Comparison in MLflow\n",
    "\n",
    "MLflow provides a powerful interface for comparing different models within the same experiment. This feature allows you to easily compare metrics like accuracy, loss, and other custom metrics across various runs. By utilizing the comparison tool, you can quickly identify which model performs best based on your specified criteria.\n",
    "\n",
    "The comparison view can be accessed from the experiment page, where you can select multiple runs and click on the \"Compare\" button. This brings up a detailed comparison view that highlights differences in parameters, metrics, and provides visualizations for quick insights.\n",
    "\n",
    "Below is an example of what the model comparison interface looks like in MLflow UI:\n",
    "\n",
    "![MLflow UI Model Comparison](./images/Screenshot2.png)\n",
    "\n",
    "This interface simplifies the task of evaluating different model versions, making it easier to make informed decisions about which model to deploy or further refine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e03da77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 26s 62ms/step\n"
     ]
    }
   ],
   "source": [
    "final_model_prediciton = loaded_ft.predict(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2df742b932880654a3f6652148a9c802dc0dfad475f6beda4797814052023f2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
